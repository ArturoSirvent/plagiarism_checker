---
title: "Comparacion semantica raices"
author: "Arturo Sirvent"
date: "11/11/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Comparación semántica.  

Identificación de plagio mediante una sencilla comparación semántica.  
La estrategia será la tokenización del texto en sus raíces semánticas, para luego realizar una comparación con las raíces semánticas del texto original.  

Primero tenemos que pre-procesar el data set, limpiarlo, guardar todos los textos limpios, eliminar las stop-words, y tokenizados según sus raíces, para finalmente hacer una comparación sencilla.

```{r}
library(tidyr)
library(tidytext)
library(dplyr)
library(tm)
library(ngram)
library(stringr)
library(readr)
```

```{r}
#cargamos los datos
load(file = "./detector_coincidencias/corpus_as_dataframe.Rda")

```

Creamos una función que deje el texto completamente limpio:


```{r}
limpiar<-function(texto){
  aux_texto<-paste(unlist(texto),collapse=" ")
  aux_texto<-tolower(aux_texto) 
  aux_texto<-gsub("[[:punct:]]"," ",aux_texto)
  aux_texto<-gsub("(\\n)|(\\t)"," ",aux_texto)
  aux_texto<-gsub("\\W"," ",aux_texto)
  #quitamos basicamente todo lo que no son letras y numeros
  aux_texto<-str_squish(aux_texto)
  aux_texto<-stringi::stri_trans_general(aux_texto,"Latin-ASCII") 
  
  return(aux_texto)
}

```

```{r}
#creamos una nueva columna para guardar los textos limpios
corpus$Text_clean<-sapply(corpus$Text,limpiar)
```


Ahora tenemos que eliminar las stop-words:

```{r}
eliminar_stopwords<-function(texto,lang="en"){
  #libreria tm
  texto_aux<-removeWords(texto,stopwords(lang))
  return(str_squish(texto_aux))
}
```

```{r}
#sobre escribimos en la columna de texto limpio, el texto sin stop-words
corpus$Text_clean<-unname(sapply(corpus$Text_clean,eliminar_stopwords))
#se estaba creando un vector con nombres y no necesitamos eso, 
#por ello applicamos el unname()
```

Ahora que tenemos el texto sin stop-words le vamos a aplicar el stemming para quedarnos con los morfemas

```{r}
steeming<-function(texto,lang="en",sep=" "){
  #libreria tm
  #necesita las palabras separadas individualmente
  texto_aux<-unlist(strsplit(texto,sep))
  texto_aux<-stemDocument(texto_aux,language = lang)
  return(as.character(unlist(texto_aux)))
}
```


```{r}
#applicamos el stemming a cada texto limpio y obtenemos un vector de morfemas
corpus$Text_clean<-unname(sapply(corpus$Text_clean,steeming))

```


Ya tenemos todas las palabras en sus raíces. El siguiente paso será contar todas las coincidencias. 


_Nota: Un problema con el que nos podríamos encontrar y que requeriría un estudio más profundo, es el tratar con los errores de ortografía. De esta manera, un plagio parcial podría pasar desapercibido por errores de escritura. La sencilla solución que proponemos es usar la función `tm_map()` de la librería `tm` para realizar una sustitución de errores comunes (usando `replaceSynonyms`)._

Tal como hemos mencionado quedaría realizar una comprobación de las coincidencias que encontramos entre los textos con supuesto plagio y los originales.  

Hacemos una función para comparar dos vectores de palabras. Esto será usado para comparar el texto supuestamente plagiado con el original.


```{r}
comparar<- function(original,plagio){
  #devolvemos las palabras que son coincidencias 
  aux_plagio<-unlist(plagio)
  aux_original<-unlist(original)
  result<-unname(aux_plagio[aux_plagio %in% aux_original ])
  if (length(result)==0){
    return(0)
  }else{
    return(result)
  }
  
}
```

Ahora que ya tenemos la función que nos hace la comparación solo debemos de crear una columna en el dataset con las coincidencias que encontremos con el original:


```{r}
#Hacemos un loop que recorra todos los registros que no son "original" y según su tipo de task
#realizamos la comparación con el original de dicha clase.
data_no_original<-corpus[corpus$Category!="original",]
#creamos un columna para ir llenando con las coincidencias
data_no_original$coincidencias<-NA

for (i in 1:nrow(data_no_original)){
  aux_task<-as.character(data_no_original$Task[i])
  text_origin_aux<-as.character(unlist(corpus[(corpus$Category=="original") 
                                              & (corpus$Task==aux_task),"Text_clean"]))
  text_plagio_aux<-data_no_original$Text_clean[[i]]
  aux_coincidencias<-comparar(text_origin_aux,text_plagio_aux)
  data_no_original$coincidencias[i]<-list(aux_coincidencias)
  
}

#hacemos la cuenta de las coincidencias al final
data_no_original$coincidencias_count<-sapply(data_no_original$coincidencias,length)

```


Una vez tenemos las coincidencias, usaremos alguna de las métricas que ya hemos usado para hacer una estimación de un porcentaje de plagio.


```{r}
#añadimos una nueva columna para hacer la cuenta del total de elementos en text_clean
data_no_original$total_words<-sapply(data_no_original$Text_clean,length)
```

Y por ultimo hacemos un porcentaje de coincidencias/total *100

```{r}
data_no_original$porcentaje<-0
for (i in 1:nrow(data_no_original)){
  data_no_original$porcentaje[i]<-100*(data_no_original$coincidencias_count[i]/
                                         data_no_original$total_words[i])
}
```

# Resultados


Veamos solo la columna de categoria, dificultad, task y porcentaje juntas:

```{r}
head(data_no_original[,c("Category","porcentaje","Task","Difficulty")],20)
```


Para los casos con mayor porcentaje: 

```{r}
head(data_no_original[data_no_original$porcentaje>80,c("Category","porcentaje","Task","Difficulty")],20)
```



Y los casos con menos pocentaje son los non:
```{r}
head(data_no_original[data_no_original$porcentaje<60,c("Category","porcentaje","Task","Difficulty")],20)
```


Tenemos algunos `cut` que no son del 100%, esto habría que ver porqué. Seguro que algo de las stop-words...
```{r}
head(data_no_original[data_no_original$porcentaje<95 & data_no_original$Category=="cut",c("Category","porcentaje","Task","Difficulty")],20)
```



Y también vemos como algunos heavy tienen un porcentaje muy bajo:
```{r}
head(data_no_original[data_no_original$porcentaje<70 & data_no_original$Category=="heavy",c("Category","porcentaje","Task","Difficulty")],20)
```


El modelo es muy sencillo pero ha dado resultados bastante prometedores al menos en la clasificación NOPLAGIO--PLAGIO.

Si ponemos 50 como limite, vemos la cantidad de plagios que se nos han colado:


```{r}
sum(data_no_original$porcentaje<50 & data_no_original$Category!="non")/sum(data_no_original$porcentaje<50)*100
```

Se nos han colado un  7.6%.


Que porcentaje de los non clasificamos bien
```{r}
sum(data_no_original$porcentaje<50 & data_no_original$Category=="non")/sum( data_no_original$Category=="non")*100
```
EL 63 % de los non están bien clasificados.

Y que porcentaje del resto se clasifican como plagio?

```{r}
sum(data_no_original$porcentaje>50 & data_no_original$Category!="non")/sum( data_no_original$Category!="non")*100
```

El 96 porciento de los plagios si se clasifican.

Pero que porcentaje de falsos positivos tenemos, estos son los que son mayor de 50% pero son non:

```{r}
sum(data_no_original$porcentaje>50 & data_no_original$Category=="non")/sum( data_no_original$porcentaje>50)*100
```
Solo un 20% se los que no debería clasificarse como plagio se clasifican como plagio.

